{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5149 S1 2020 Assessment 1: Bushfire Analysis using Meteorological Data\n",
    "\n",
    "\n",
    "Student information\n",
    "- Family Name: Muralitharan\n",
    "- Given Name: Keerthana\n",
    "- Student ID: 30159474\n",
    "- Student email: kmur0015@student.monash.edu\n",
    "\n",
    "Programming Language: R 3.3 in Jupyter Notebook\n",
    "\n",
    "R Libraries used:\n",
    "- dplyr\n",
    "- kernlab\n",
    "- caret\n",
    "- ggplot\n",
    "- MASS\n",
    "- leaps\n",
    "- randomForest\n",
    "- corrplot\n",
    "- tidyverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages('kernlab')\n",
    "#install.packages('e1071')\n",
    "#install.packages('tidyverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "require(kernlab)\n",
    "require(caret)\n",
    "library(e1071)\n",
    "library(ggplot2)\n",
    "library(MASS)\n",
    "library(leaps)\n",
    "library(randomForest)\n",
    "library(corrplot)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#sec_1)\n",
    "* [Data Exploration](#sec_2)\n",
    "* [Model Development](#sec_3)\n",
    "* [Model Comparison](#sec_4)\n",
    "* [Variable Identification and Explanation](#sec_5)\n",
    "* [Conclusion](#sec_6)\n",
    "* [References](#sec_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a class=\"anchor\" id=\"sec_1\"></a>\n",
    "\n",
    "This assessment involves 2 tasks to be performed namely the **prediction** task and the **Description** task.\n",
    "\n",
    "**Prediction Task**\n",
    "\n",
    "- In this task, The burned area due to bush fires in between 2000 and 2003 at Portugal using the meteorological data by developing 3 models - **Linear Regression model, Support Vector Regression model and Random Forest Regressor model** and choosing the best model to predict the burned area\n",
    "\n",
    "**Description Task**\n",
    "\n",
    "-In this task, the best suited features in the model is identified and its significance and importance is mentioned.\n",
    "\n",
    "\n",
    "#### Understanding the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the forestfires.csv input file and displaying the dimensions of the file\n",
    "forestdata <-  read.csv('forestfires.csv', header = TRUE, sep = \",\", stringsAsFactors=FALSE)\n",
    "bushdata<-forestdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dimensions\n",
    "cat(\"The housing dataset has\", dim(forestdata)[1], \"records, each with\", dim(forestdata)[2],\"attributes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"The attribute names of the forest fire dataset are \\n\")\n",
    "# Display the column(attribute) names \n",
    "colnames(forestdata)\n",
    "cat(\"The structure of the forest fire data is \\n\\n\")\n",
    "# Display the structure\n",
    "str(forestdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### OBSERVATION :\n",
    "\n",
    "\n",
    "<li>Month, Day are <b>Categorical</b> Attribute</li>\n",
    "<li>X, Y, FFMC, RH, wind, rain,DMC, DC, ISI, Temp and are <b>numerical</b> attributes</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\nBelow is the small portion of how the dataset appears:\")\n",
    "# Display the first few records\n",
    "head(forestdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\nBelow is the sumary for each attribute are:\")\n",
    "\n",
    "summary(forestdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration<a class=\"anchor\" id=\"sec_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if any data missing.\n",
    "sum(is.na(forestdata))\n",
    "\n",
    "# Check to see how many cases have an area of 0\n",
    "cat(\"\\nNumber of bush fire cases where burned area is zero:\")\n",
    "length(which(forestdata$area==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of Categorical Variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the month \n",
    "forestfires_month <- forestdata %>% group_by(month) %>% summarize(fires=n())\n",
    "#filtering the day\n",
    "forestfires_day <- forestdata %>% group_by(day) %>% summarize(fires=n())\n",
    "\n",
    "#the months are factorised and assigned the values\n",
    "forestfires_month <- forestfires_month %>%\n",
    "  mutate(month = factor(month, levels = c(\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\")))\n",
    "#the days are factorised and assigned the values\n",
    "forestfires_day <- forestfires_day %>%\n",
    "  mutate(day = factor(day, levels = c(\"mon\", \"tue\", \"wed\", \"thu\", \"fri\", \"sat\", \"sun\")))\n",
    "\n",
    "#monthwise and daywise plot is plotted\n",
    "fires_by_month <- ggplot(data=forestfires_month) + aes(x=month,y=fires) + geom_bar(stat=\"identity\",color='blue',fill='skyblue') + labs(title = \"Fires by Month\", x = \"Month\", y =\"Number of fires\") \n",
    "fires_by_day <- ggplot(data=forestfires_day) + aes(x=day,y=fires) + geom_bar(stat=\"identity\",color='blue',fill='skyblue') + labs(title = \"Fires by Day\", x = \"Day\", y =\"Number of fires\")\n",
    "\n",
    "#month plot versus total number of bushfires\n",
    "fires_by_month\n",
    "#month plot versus total number of bushfires\n",
    "fires_by_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing the discrete vars\n",
    "##Creating a new data set where area is less than 300\n",
    "catforest <- forestdata %>% filter((area < 300))\n",
    "index <- unlist(lapply(catforest, is.numeric))\n",
    "forest <- cbind(catforest[ , c(!index)],catforest$area)\n",
    "names(forest) <- c('Month','Day','area')\n",
    "print(head(forest))\n",
    "mat <- table(forest$Month,forest$Day)\n",
    "options(repr.plot.res = 100,repr.plot.width=18, repr.plot.height=10)\n",
    "mosaicplot(mat,main = \"Distribution of Days in Month\", col=c(1,2,3,4,5,6,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation :\n",
    "\n",
    "- We see that high number of the bush fires occur in the month of **August and September**.\n",
    "\n",
    "- In the case of day, **Friday,saturday,sunday and monday** have more number of bushfires\n",
    "\n",
    "- On day-wise accidents for the week , all the days have >60 bushfires with almost same level of bushfires.\n",
    "\n",
    "- The mosaic plot for the area affected in different Months shows in **january,november and may** do not have much bush fires and other months having less than 50 bush fires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the relationship between burn area and park location\n",
    "\n",
    "burn_coord = forestdata %>% group_by(X, Y) %>% summarize(area_mean = mean(area))\n",
    "ggplot(burn_coord, aes(x = factor(X), y = factor(Y),\n",
    "       fill = area_mean)) + geom_tile() + scale_fill_gradient2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "Based on the above heat map , the co-ordinates (X,Y)-(8,8) has more average bush fires compared to the other locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert month and day string variables into numeric values(Categorical to Numerical conversion)\n",
    "forestdata$month <- as.numeric(as.factor(forestdata$month))\n",
    "forestdata$day <- as.numeric(as.factor(forestdata$day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(1,1))\n",
    "#plot a correlation plot for the variables\n",
    "M <- cor(forestdata)\n",
    "corrplot(M, method=\"color\", outline = TRUE,type=\"lower\",order = \"hclust\",\n",
    "         number.cex = 1.0,addCoef.col = \"black\",\n",
    "         tl.col=\"black\", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),\n",
    "         title=\"Correlation plot between Predictor and Outcome variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation :\n",
    "Based on the correlation plot we have examined the correlations between all the 13 variables where we can see a number of important correlations which we may want to account for in our model.\n",
    "- Positive correlations between ISI, temp, DCM and DC\n",
    "- Positive correlations between X and Y\n",
    "- Negative correlations between RH and Temp\n",
    "\n",
    "Also the Area outcome variable isnâ€™t strongly correlated to any of 12 variables.\n",
    "\n",
    "- positive DC&DMC - high correlation with 0.68\n",
    "- positive temp &DMC - high correlation with 0.5\n",
    "- negative RH & temp - negative high correlation with -0.53\n",
    "    \n",
    "**while selecting the features if (DC,DMC) or (temp,DMC) and (RH,temp) appear together anyone of the variable is neglected to avoid multi-collinearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting boxplots for all the 13 variable\n",
    "par(mfrow = c(3,5)) # 5 x 3 grid\n",
    "for (i in 1:(length(forestdata))) {\n",
    "        boxplot(forestdata[,i], main = names(forestdata[i]), type=\"l\", col = 'maroon') \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation \n",
    "\n",
    "From the above boxplots we can observe outliers with the folowing variables\n",
    "\n",
    "<li>area\n",
    "<li>FFMC\n",
    "<li>ISI\n",
    "<li>rain\n",
    "\n",
    "However, the above outliers are not error values so we have not removed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot is created for all the 12 input model variables to understand its skewness\n",
    "par(mfrow=c(2,6),mar=c(3.50, 1, 2.5, 2.5))\n",
    "for (variables in 1:(dim(forestdata)[2]-1)){\n",
    "  thisvar = forestdata[,variables]\n",
    "  d <- density(thisvar)\n",
    "  plot(d, main = names(forestdata[variables]),xlab=\"\")\n",
    "  polygon(d, col=\"pink\", border=\"red\")\n",
    "  title(\"Density plots for all 12 Model Variables\", line = -27, outer = TRUE)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation \n",
    "\n",
    "The above matrix of density plots shows us  that the <b>rain,ISI</b> are right skewed and <b>FFMC</b> is left skewed while  we could observe a normal (gaussian) distributions for <b>temp, wind, RH, X, DMC and day</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot for the target variable - area\n",
    "d <- density(forestdata$area)\n",
    "plot(d)\n",
    "polygon(d, col=\"skyblue\", border=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "Based on the above density plot on area we could it is right skewed with more number of zeroes also it has some outlier with area above 300 which can be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removal of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the area value in decreasing order to find the outliers\n",
    "cat(\"Area value in decreasing order\\n \")\n",
    "sort(forestdata$area, decreasing = TRUE)[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are two particularly large area values of 1090.84 and 746.28 above 300. These 2 outlier values are removed from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the outliers\n",
    "forestdata <- forestdata %>% filter((area < 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Transformations\n",
    "\n",
    "Based on the boxplots and density plots, we can use **reflected log transform for FFMC** and **log transform of rain** and **log transform for area**, since the area is highly concentrated towards zero and assymetrical.\n",
    "\n",
    "we can see from the graph that burned area is highly skewed with lots of 0 values so performing log transformation to the burnt area to reduce skewness. we need to transform the target variable 'area' and input variable 'rain' by taking its logarithm (after adding 1 to avoid zeros)\n",
    "$$\\text{Log-area} = log_{10}(area+1)$$\n",
    "$$\\text{Log-rain} = log_{10}(rain+1)$$\n",
    "$$\\text{Log-area} = log_{10}(max(FFMC+1)-FFMC)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Log transformation for FFMC variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.datanovia.com/en/lessons/transform-data-to-normal-distribution-in-r/\n",
    "\n",
    "#reflected log trasformation for FFMC variable\n",
    "forestdata$ref_log_FFMC <- log10(max(forestdata$FFMC+1)-forestdata$FFMC)\n",
    "forestdata <- subset(forestdata, select = -c(FFMC))\n",
    "#Plotting the histogram after transformation\n",
    "ggplot(forestdata, aes(x = ref_log_FFMC)) + geom_histogram(color='black',fill='skyblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log transformation for rain variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transformation of the rain variable\n",
    "forestdata$log_rain <- log10(forestdata$rain+1)\n",
    "forestdata <- subset(forestdata, select = -c(rain))\n",
    "\n",
    "#Plotting graph after transformation\n",
    "ggplot(forestdata, aes(x = log_rain)) + geom_histogram(color='black',fill='skyblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Observation\n",
    "- It is clear that after reflected log- transformation we could see a normal distribution with the FFMC , whereas there is not much of a difference with rain variable because there are very few like 5 values have some numerical values leaving the rest with zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding for Month and Day categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding is performed to month variable \n",
    "for(unique_value in unique(forestdata$month)){\n",
    "\n",
    "forestdata[paste(\"month\", unique_value, sep = \".\")] <- ifelse(forestdata$month== unique_value, 1, 0)\n",
    "\n",
    "}\n",
    "#After the encoding the month variable from the dataset is removed\n",
    "forestdata <- subset(forestdata, select = -c(month))\n",
    "\n",
    "#One-hot encoding is performed to the day variable\n",
    "\n",
    "for(unique_value in unique(forestdata$day)){\n",
    "\n",
    "forestdata[paste(\"day\", unique_value, sep = \".\")] <- ifelse(forestdata$day== unique_value, 1, 0)\n",
    "\n",
    "}\n",
    "\n",
    "#After the encoded values are filled in the data , the day variable is removed\n",
    "forestdata <- subset(forestdata, select = -c(day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log transformation for target variable- AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transformation for area variable\n",
    "forestdata$log_area <- log10(forestdata$area+1)\n",
    "forestdata <- subset(forestdata, select = -c(area))\n",
    "#plot the area variable after transformation\n",
    "ggplot(forestdata, aes(x = log_area)) + geom_histogram(color='black',fill='skyblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the log transformation is applied to the area varible, we could see a gaussian distribution excluding the zeroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sample the dataset.\n",
    "set.seed(90)\n",
    "#main dataset is split in 80:20 into train and test datasets by setting a index\n",
    "row.number <- sample(1:nrow(forestdata), 0.8*nrow(forestdata))\n",
    "#Split to train and test dataset\n",
    "bushtrain = forestdata[row.number,]\n",
    "bushtest = forestdata[-row.number,]\n",
    "\n",
    "#display the rows of the datasets.\n",
    "cat(\"Number of rows in dataset\\t:\",nrow(forestdata))\n",
    "cat(\"\\nNumber of rows in train dataset\\t:\",nrow(bushtrain))\n",
    "cat(\"\\nNumber of rows in test dataset\\t:\",nrow(bushtest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1. Linear Regression\n",
    "\n",
    "Based on the exploration we were not able to guess the variables which must be used for building the models,therefore we do a subset selection for linear regression is done using **stepwise** regression using **sequential replacement** and **nvmax=9**.Once the features are selected, the linear model is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Stepwise regression to find the significant variables affexting the area\n",
    "models <- regsubsets(log_area~., data = bushtrain, nvmax = 9,method = \"seqrep\")\n",
    "\n",
    "#display the summary of the stepwise regression\n",
    "summary(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features selected for the linear regression are \n",
    "DMC,temp,wind,months - (12,1,4,3 and 9 which are dec,jan,apr,mar and sep) and day1,5-(monday and friday)\n",
    "\n",
    "#### Building the linear regression with selected features\n",
    "\n",
    "The linear model is built for all the above selected variables against the log_area for the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the linear regression model with features obtained from feature selection\n",
    "linear_model <-lm(log_area ~ DMC + temp + wind +month.12 +month.1+month.4+month.3+month.9+day.1+day.5, data = bushtrain )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of the model\n",
    "summary(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "\n",
    "All the varibles excluding month.9(sep) and day.1(monday) , all other are important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2.Random Forest Regressor\n",
    "\n",
    "The second model is Random forest regressor which is set to be built for the dataset to predict the log_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest model with all the variables\n",
    "random_forest<- randomForest(log_area ~ .,  data = bushtrain, ntree=500)\n",
    "#summary of the model\n",
    "random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Finding the Important varibles used for random forest to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the variables which are most important.\n",
    "importance(random_forest)[order(-importance(random_forest)),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "**temp,RH,DMC,DC,wind** are the most 5 important variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the variable importance\n",
    "varImpPlot(random_forest,pch=18,col=\"blue\",cex=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "Based on the above plot we can find **temp,RH,DMC,DC,FFMC,wind and ISI** are most important.To avoid the multi-collinearity we can ignore **RH and DC** as temp is more important than RH and DMC is more important than DC.\n",
    "#### Tuning the random forest regressor\n",
    "Before we model the random forest we must determine the best  model by selecting **the mtry - preselected directions used in splitting,and number of trees, and the maximum nodesize** for the random forest regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the mtry value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.guru99.com/r-random-forest-tutorial.html\n",
    "#setting the k-fold cross validation\n",
    "trControl <- trainControl(method='cv',number=10,search=\"grid\")\n",
    "# to find the best mtry\n",
    "rf_default <- train(log_area~.,\n",
    "    data = bushtrain,\n",
    "    method = \"rf\",\n",
    "    trControl = trControl)\n",
    "# Print the results\n",
    "print(rf_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the  best maxnode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.guru99.com/r-random-forest-tutorial.html\n",
    "#search the best maxnode\n",
    "store_maxnode <- list()\n",
    "tuneGrid <- expand.grid(.mtry = 2)\n",
    "for (maxnodes in c(5: 20)) {\n",
    "    #train the model to find the maximum node\n",
    "    rf_maxnode <- train(log_area~.,\n",
    "        data = bushtrain,\n",
    "        method = \"rf\",\n",
    "        tuneGrid = tuneGrid,\n",
    "        trControl = trControl,\n",
    "        importance = TRUE,\n",
    "        nodesize = 14,\n",
    "        maxnodes = maxnodes,\n",
    "        ntree = 500)\n",
    "    current_iteration <- toString(maxnodes)\n",
    "    store_maxnode[[current_iteration]] <- rf_maxnode\n",
    "}\n",
    "results_mtry <- resamples(store_maxnode)\n",
    "#display the summary\n",
    "summary(results_mtry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for value **maxnode=14** the mean of errors are less comaratively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### selecting the best ntree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.guru99.com/r-random-forest-tutorial.html\n",
    "#search best ntrees\n",
    "store_maxtrees <- list()\n",
    "\n",
    "#train the model to find the best number of trees \n",
    "for (ntree in c(250, 300, 350, 400, 450, 500, 550, 600, 800, 1000, 2000)) {\n",
    "    rf_maxtrees <- train(log_area~.,\n",
    "        data = bushtrain,\n",
    "        method = \"rf\",\n",
    "        tuneGrid = tuneGrid,\n",
    "        trControl = trControl,\n",
    "        importance = TRUE,\n",
    "        nodesize = 14,\n",
    "        maxnodes = 24,\n",
    "        ntree = ntree)\n",
    "    key <- toString(ntree)\n",
    "    store_maxtrees[[key]] <- rf_maxtrees\n",
    "}\n",
    "results_tree <- resamples(store_maxtrees)\n",
    "#display the summary\n",
    "summary(results_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the value **ntree=250**, the mean errors are less.\n",
    "Based on the above results.the best values are\n",
    "\n",
    "- **mtry**=2\n",
    "- **maxnode**=14\n",
    "- **ntree**=250\n",
    "\n",
    "Using these values, we can train the model to the features selected based on its importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the variable importance and tuned parameters Random forest is built\n",
    "random_forest_rf<-randomForest(log_area~temp+DMC+ref_log_FFMC+wind+ISI, data=bushtrain,ntree=250,mtry=2,maxnodes=14)\n",
    "\n",
    "#summary of random forest\n",
    "random_forest_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning the Random forest regressor we could find that the **mean of squared residuals** and **percentage of variance** has improved from **0.3832 to 0.354** and **-11.16 to -2.7** respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3. Support Vector Regressor\n",
    "\n",
    "The third model is Support vector regressor which is built in order to predict the log_area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a svr model -radial kernel with all the variables\n",
    "svr_model =svm(log_area ~ .,data=bushtrain)\n",
    "\n",
    "#summary of the model\n",
    "svr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection based on Recursive feature elimination method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datasciencebeginners.com/2018/11/26/functions-and-packages-for-feature-selection-in-r/\n",
    "set.seed(86)\n",
    "\n",
    " \n",
    "# Setting the cross validation parameters\n",
    "ctrl_param <- rfeControl(functions = rfFuncs,\n",
    "                   method = \"repeatedcv\",\n",
    "                   repeats = 5,\n",
    "                   verbose = FALSE,\n",
    "                   returnResamp = \"all\")\n",
    " \n",
    "#using RFE choosing the top variables\n",
    "rfe_lm_profile <- rfe(bushtrain[,-30], bushtrain[,30],\n",
    "                 sizes = c(2,30),\n",
    "                 rfeControl = ctrl_param,\n",
    "                 newdata = bushtest[,-30])\n",
    "\n",
    "#display the summary\n",
    "rfe_lm_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top variables are **DMC,DC,temp,month.3(mar),month.2(feb)**. since DMC and DC are highly correlated and to avoid collinearity we would consider only **DMC,temp,month.3 and month.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the model to find the best cost and gamma value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html\n",
    "options(warn=-1)\n",
    "\n",
    "#Tuning SVR model by varying values of maximum allowable error and cost parameter\n",
    "#Tune the SVM model\n",
    "OptModelsvm=tune(svm,log_area~., data=bushtrain,ranges=list(elsilon=seq(0,5,1), cost=seq(0.1,2,0.1)))\n",
    "\n",
    "#Print optimum value of parameters\n",
    "print(OptModelsvm)\n",
    "\n",
    "#Plot the perfrormance of SVM Regression model\n",
    "plot(OptModelsvm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above R code is used in the tuning of the SVR model by changing the maximum error which is allowable and parameter cost. The tuning function determines the performance of 100 models (20*5) i.e. for every value of cost parameter (0.1 to 2) vs  maximum allowable error (0 -5) . The OptModelsvm has epsilon and cost as 0.1 and 0.4  respectively.The best model has lower MSE. the lower the MSE,the darker is the region, which means the model is better. In our subset of data,the MSE is low at epsilon value 0.1 and cost value 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the best tuned model \n",
    "BstModel=OptModelsvm$best.model\n",
    "BstModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-model with the features selected and tuned parameters\n",
    "svr_model_new =svm(log_area ~ DMC+temp+month.3+month.2,data=bushtrain,cost=0.4,epsilon=0.1)\n",
    "#display the summary\n",
    "svr_model_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above 2 svr models we can come to a conclusion that the model with all the variables is better when compared to the model with features selected.The increase in gamma value from **0.0344** to **0.25** tells us the first full model is to be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparsion<a class=\"anchor\" id=\"sec_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the burnt area using 3 models built.\n",
    "\n",
    "##### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the area using linear model\n",
    "linear_predict<-predict(linear_model, newdata = bushtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the metrics\n",
    "cat(\"Metrics of Linear regression\\n\")\n",
    "cat(\"RMSE\\t:\",RMSE(linear_predict, bushtest$log_area))\n",
    "cat(\"\\nR-squared:\",R2(linear_predict, bushtest$log_area))\n",
    "cat(\"\\nMAE\\t:\",MAE(linear_predict, bushtest$log_area))\n",
    "cat(\"\\nVariance\",var(linear_predict,bushtest$log_area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the burned area using random forest\n",
    "random_forest_predict <- predict(random_forest_rf,newdata=bushtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the metrics\n",
    "cat(\"Metrics of Random Forest\\n\")\n",
    "cat(\"RMSE\\t:\",RMSE(random_forest_predict,bushtest$log_area))\n",
    "cat(\"\\nR-squared:\",R2(random_forest_predict,bushtest$log_area))\n",
    "cat(\"\\nMAE\\t:\",MAE(random_forest_predict,bushtest$log_area))\n",
    "cat(\"\\nvariance:\",var(random_forest_predict,bushtest$log_area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the burned area using the svr\n",
    "svr_predict<- predict(svr_model_new,newdata=bushtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the metrics\n",
    "cat(\"Metrics of Support Vector regreesor\\n\")\n",
    "cat(\"RMSE\\t:\",RMSE(svr_predict,bushtest$log_area))\n",
    "cat(\"\\nR-squared:\",R2(svr_predict,bushtest$log_area))\n",
    "cat(\"\\nMAE\\t:\",MAE(svr_predict,bushtest$log_area))\n",
    "cat(\"\\nVAriance:\",var(svr_predict,bushtest$log_area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to calculate the RMSE,R^2,MSE,MAE and variance for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate RMSE\n",
    "rmse<- function(pred){\n",
    "    RMSE=round(RMSE(pred, bushtest$log_area),5)\n",
    "    return(RMSE)\n",
    "}\n",
    "\n",
    "#function to calculate MSE\n",
    "mse<- function(pred){\n",
    "    MSE=round(sum((pred - bushtest$log_area)^2)/length(pred),5)\n",
    "    return(MSE)\n",
    "}\n",
    "\n",
    "#function to calculate MAE\n",
    "mae<- function(pred){\n",
    "    MAE=round(MAE(pred, bushtest$log_area),5)\n",
    "    return(MAE)\n",
    "}\n",
    "\n",
    "#function to calculate variance\n",
    "vari<- function(pred){\n",
    "    var=round(var(pred, bushtest$log_area),5)\n",
    "    return(var)\n",
    "}\n",
    "\n",
    "#function to calculate R-squared\n",
    "r2<- function(pred){\n",
    "    R2=round(R2(pred, bushtest$log_area),5)\n",
    "    return(R2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Storing the model name and metrics in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.c-sharpcorner.com/article/r-data-frame-operations-adding-rows-removing-rows-and-merging-two-data-frame/\n",
    "Model <-c(\"Linear Regression\",\"Random Forest\",\"Support Vector Regression\") # model name\n",
    "RMSE <-c(rmse(linear_predict),rmse(random_forest_predict),rmse(svr_predict)) # RMSE\n",
    "R.squared <-c(r2(linear_predict),r2(random_forest_predict),r2(svr_predict)) # R-squared\n",
    "MSE <- c(mse(linear_predict),mse(random_forest_predict),mse(svr_predict)) # MSE\n",
    "MAE <- c(mae(linear_predict),mae(random_forest_predict),mae(svr_predict)) #MAE\n",
    "variance <- c(vari(linear_predict),vari(random_forest_predict),vari(svr_predict)) # Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dataframe binded with the models and metrics\n",
    "Metric <- data.frame(Model,RMSE,R.squared,MSE,MAE,variance)\n",
    "# disply the metric dataframe\n",
    "Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Displaying the metrics for the models in the form of barplots\n",
    "\n",
    "##### 1. RMSE\n",
    "Root Mean Square Error (RMSE) quantifies the error between two datasets namely the test and train.it compares a predicted value and known value. The smaller the RMSE value, the values predicted and observed values are closely matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a bargraph for RMSE\n",
    "barplot(height=Metric$RMSE, names=Metric$Model, \n",
    "        col='SkyBlue',\n",
    "        xlab=\"Model\", \n",
    "        ylab=\"values\", \n",
    "        main=\"RMSE\", \n",
    "        ylim=c(0.0,0.65)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. MSE\n",
    "\n",
    "MSE is the mean of the squared error that is used as the loss function for least squares regression: It is the sum, over all the data points, of the square of the difference between the predicted and actual target variables, divided by the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a bar graph for MSE\n",
    "barplot(height=Metric$MSE, names=Metric$Model, \n",
    "        col='SkyBlue',\n",
    "        xlab=\"Model\", \n",
    "        ylab=\"values\", \n",
    "        main=\"MSE\", \n",
    "        ylim=c(0.0,0.40)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.MAE\n",
    "\n",
    "MAE is the average absolute vertical or horizontal distance between each  data point in a scatter plot and the Y=X line.MAE is the average absolute difference between X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a bargraph for MAE\n",
    "barplot(height=Metric$MAE, names=Metric$Model, \n",
    "        col='SkyBlue',\n",
    "        xlab=\"Model\", \n",
    "        ylab=\"values\", \n",
    "        main=\"MAE\", \n",
    "        ylim=c(0.0,0.50)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Variance\n",
    "Variance is the type of errors that occurs due to a model's sensitivity to small fluctuations in the training dataset.High variance in model would create the noise in the training dataset, which is commonly referred as overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a barplot for variance\n",
    "barplot(height=Metric$variance, names=Metric$Model, \n",
    "        col='SkyBlue',\n",
    "        xlab=\"Model\", \n",
    "        ylab=\"values\", \n",
    "        main=\"Variance\", \n",
    "        ylim=c(0.0,0.10)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5 . R-squared\n",
    "\n",
    "R-squared (R2) is a measure which represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the R-squared values in a bargraph\n",
    "barplot(height=Metric$R.squared, names=Metric$Model, \n",
    "        col='SkyBlue',\n",
    "        xlab=\"Model\", \n",
    "        ylab=\"values\", \n",
    "        main=\"R-squared\", \n",
    "        ylim=c(0.0,0.05)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "- When comparing the **RMSE** for the three models, we have less errors in **Random Forest**\n",
    "- When comparing the **MSE** for the three models, we have less errors in **Random Forest**\n",
    "- When comparing the **MAE** for the three models, we have less errors in **Support Vector Regression**\n",
    "- When comparing the **Variance** for the three models, we have variance in **Random forest**\n",
    "- When comparing the **R-square** for the three models, we have high value in **Support Vector Regression**\n",
    "\n",
    "Based on the above metrics we could say that the **Random Forest** is better when compared to the other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Variable Identification and Explanation <a class=\"anchor\" id=\"sec_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we were not able to consider any variables to develop from our Exploratory Data analysis, we have performed feature selection to build better models.We could see a considerable improvement in some of our models after selecting certain features to build the model.\n",
    "\n",
    "### 1. Linear model variable identification \n",
    "\n",
    "For the linear regression we have used **stepwise** in **sequential replacement(seqrep)** mode to get the best features and we\n",
    "have selected **DMC,temp,wind,month and day**\n",
    "\n",
    "-> lm(log_area ~ DMC + temp + wind +month.12 +month.1+month.4+month.3+month.9+day.1+day.5, data = bushtrain )\n",
    "\n",
    "### 2. Random forest variable identification\n",
    "\n",
    "For random forest we have used the **variable importance** - **varImp** to select the features for the model which resulted in these variables **temp,DMC,RH,DC,FFMC,wind and ISI** - we have removed DC and RH to avoid collinearity issues.\n",
    "\n",
    "-> randomForest(log_area~temp+DMC+ref_log_FFMC+wind+ISI, data=bushtrain,ntree=250,mtry=2,maxnodes=14)\n",
    "\n",
    "### 3. Support Vector Regressor variable identification\n",
    "\n",
    "For the supprt vector regressor, we have used the **Recursive Feature Selection** and got 5 top variables which are **DMC,DC,temp,month**, as discussed earlier we have removed DC to avoid collinearity issues.\n",
    "\n",
    "-> svr_model_new =svm(log_area ~ DMC+temp+month.3+month.2,data=bushtrain,cost=0.4,epsilon=0.1)\n",
    "\n",
    "But the above svr model did not give any improvement to the model, therefore the full model with all the variables is considered to be the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion <a class=\"anchor\" id=\"sec_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these 3 models built, we could say that the **Random Forest** is the best model as it had considerable amount of low errors and a proper fit with the features selected based on **variable Importance**.\n",
    "\n",
    "As far as the given bushfire dataset is considered, the three models developed are not a good fit to the dataset as the\n",
    "regression measures calcuated are not as expected for all the models. This issue can be resolved by \n",
    "- Having more data in the dataset that could improve the quality of prediction\n",
    "- Exploring more complex algorithms such as Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. References <a class=\"anchor\" id=\"sec_7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data analysis**\n",
    "- https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html\n",
    "- https://rstudio-pubs-static.s3.amazonaws.com/547492_3001dd3441ab47d7989f5fe529a95868.html\n",
    "- https://stats.stackexchange.com/questions/56678/analyzing-reflected-and-transformed-variables\n",
    "- https://www.datanovia.com/en/lessons/transform-data-to-normal-distribution-in-r/\n",
    "\n",
    "**Data Transformation**\n",
    "- https://www.datanovia.com/en/lessons/transform-data-to-normal-distribution-in-r/\n",
    "- https://www.analytics-link.com/post/2017/08/25/how-to-r-one-hot-encoding\n",
    "\n",
    "**Feature Selection**\n",
    "- https://www.youtube.com/watch?v=-2DlAMYioqY\n",
    "- https://stackoverflow.com/questions/51999898/how-do-i-generate-a-decision-tree-plot-and-a-variable-importance-plot-in-random\n",
    "- https://dataaspirant.com/2018/01/15/feature-selection-techniques-r/\n",
    "- http://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf\n",
    "- https://datasciencebeginners.com/2018/11/26/functions-and-packages-for-feature-selection-in-r/\n",
    "- https://dataaspirant.com/2018/01/15/feature-selection-techniques-r/\n",
    "\n",
    "**Model Development & Metric Calculations**\n",
    "- http://www.sthda.com/english/articles/38-regression-model-validation/158-regression-model-accuracy-metrics-r-square-aic-bic-cp-and-more/\n",
    "- https://towardsdatascience.com/random-forest-in-r-f66adf80ec9\n",
    "- https://topepo.github.io/caret/recursive-feature-elimination.html\n",
    "- https://uc-r.github.io/random_forests\n",
    "- http://ugrad.stat.ubc.ca/R/library/randomForest/html/randomForest.html\n",
    "- https://www.guru99.com/r-random-forest-tutorial.html\n",
    "- https://topepo.github.io/caret/variable-importance.htmli\n",
    "- https://www.listendata.com/2014/11/random-forest-with-r.html\n",
    "- https://www.researchgate.net/post/what_is_the_acceptable_r-squared_value\n",
    "- https://www.svm-tutorial.com/2014/10/support-vector-regression-r/\n",
    "- https://datasciencebeginners.com/2018/11/26/functions-and-packages-for-feature-selection-in-r/\n",
    "- https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html\n",
    "- http://www.columbia.edu/~yh2693/ForestFire.html\n",
    "- https://www.c-sharpcorner.com/article/r-data-frame-operations-adding-rows-removing-rows-and-merging-two-data-frame/\n",
    "- https://www.investopedia.com/terms/r/r-squared.asp\n",
    "- https://datascience.stackexchange.com/questions/37345/what-is-the-meaning-of-term-variance-in-machine-learning-model\n",
    "- https://en.wikipedia.org/wiki/Mean_absolute_error\n",
    "- https://www.oreilly.com/library/view/machine-learning-with/9781785889936/669125cc-ce5c-4507-a28e-065ebfda8f86.xhtml\n",
    "- https://gisgeography.com/root-mean-square-error-rmse-gis/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir3.3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
